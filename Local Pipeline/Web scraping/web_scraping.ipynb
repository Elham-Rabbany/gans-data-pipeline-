{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSQ5Fev3rZ2M"
   },
   "source": [
    "# Web scraping\n",
    "\n",
    "Web scraping is a technique used to extract data from websites. It involves sending HTTP requests to websites, parsing the returned HTML code, and extracting the desired data. Web scraping is a powerful tool for data scientists as it allows them to collect large amounts of data from the web. This data can then be used to train machine learning models, analyse trends, and make informed business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktDmVq208N_-"
   },
   "source": [
    "---\n",
    "## 1.&nbsp; Import libraries üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wL77EPUT7tc6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg2dCwV69i6u"
   },
   "source": [
    "---\n",
    "## 2.&nbsp; Beautiful Soup üç≤\n",
    "\n",
    "[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a Python library that simplifies the process of web scraping. It provides a user-friendly interface for parsing HTML documents, enabling users to extract specific information from websites. Through Beautiful Soup, you can navigate the HTML tree structure, locate elements based on their tags, attributes, and content, and extract the desired data into a structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWYO44DoBamu"
   },
   "source": [
    "To illustrate how to use Beautiful Soup, we'll use the simplified mock website below. This stripped-down version serves as a practical learning tool, as real websites often possess much larger and more complex HTML structures. By starting with this simplified model, you can gradually build your skills and expertise, ensuring a solid understanding of the core concepts before tackling more intricate web scraping tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jl6v_XhL1t0-"
   },
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\" meta=\"Middle sister\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfSTZsHAClN-"
   },
   "source": [
    "\n",
    "Beautiful Soup's HTML parser takes the raw, unruly HTML code and transforms it into a neatly organised tree structure, making the information easily accessible and manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXuMlTd014SF"
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoPKtzURCmMu"
   },
   "source": [
    "We can see the tree structure using Beautiful Soup's `.prettify` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxpOiIou-KwF",
    "outputId": "28b74c88-548b-4a53-b069-a85afe7b004a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXAo3MBl8oy9"
   },
   "source": [
    "---\n",
    "## 3.&nbsp; Navigating html for beginners üß≠\n",
    "There are many methods in Beautiful Soup to explore the html data. By far the most popular and useful of these is .find_all(). So, naturally, this is where we'll start our journey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLDnNzZ08scc"
   },
   "source": [
    "### 3.1.&nbsp; `.find_all()`\n",
    "The `.find_all()` method in Beautiful Soup returns a list of all the elements that match the specified criteria, such as tag name, class name, or attribute values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4eVS1rUAp9D"
   },
   "source": [
    "#### 3.1.1.&nbsp; Searching by tag\n",
    "\n",
    "The tags are the letter/word at the beginning of the angle brackets. For example, below, these brackets have an `a` tag.\n",
    "\n",
    "`<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>`\n",
    "\n",
    "The `.find_all()` method takes a string argument and returns a list of all matching HTML tags within the current document. If no matching tags exist, an empty list is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJFWDbHmf6ur",
    "outputId": "1e62de7b-00de-4e16-e8dd-b3bf7b5b036f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqrujkXd8qK5",
    "outputId": "a3d81e37-3a0f-405a-e759-7c32e06fb78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"><b>The Dormouse's story</b></p>,\n",
       " <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a> and\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>;\n",
       " and they lived at the bottom of a well.</p>,\n",
       " <p class=\"story\">...</p>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7elwgBfA5GW"
   },
   "source": [
    "#### 3.1.2.&nbsp; Searching by attribute\n",
    "\n",
    "Attributes are the other information in the angle brackets. For example, below, these brackets have a `class`, `href`, `id`, and `meta` attribute.\n",
    "\n",
    "`<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>`\n",
    "\n",
    "Attributes provide additional context and functionality to the elements. They can serve various purposes, including CSS selectors for styling, URLs for linking to external resources, metadata for storing relevant data, and a multitude of other information-bearing components. By leveraging these attributes, we can effectively target specific sections of the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4SZY8Z8hAA0"
   },
   "source": [
    "##### 3.1.2.1.&nbsp; CSS selectors\n",
    "CSS selectors are used to to style certain sections of websites. This makes them very helpful for webscraping as we can then target certain regions of the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yoarw3ghEe0"
   },
   "source": [
    "###### 3.1.2.1.1.&nbsp; Class\n",
    "Class selectors are used to style **multiple** HTML elements that share a common characteristic or function.\n",
    "> **Note:** here class has an underscore at the end of the word, this is because class is a reserved keyword in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_amindGhC13",
    "outputId": "30da2319-ca60-46ad-8d00-d5b899718bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"sister\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfFFv08whDET"
   },
   "source": [
    "###### 3.1.2.1.2.&nbsp; ID\n",
    "ID selectors are used to style **single** HTML elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZRqX1fhhC4h",
    "outputId": "aa17b01a-8394-482f-b39f-9e925e6f9548"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"link1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUmznwLq2Wbi",
    "outputId": "d9ab8e06-6e04-4145-9e3c-6e9d4363de5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"link2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrh1aU9f-7z4"
   },
   "source": [
    "##### 3.1.2.2.&nbsp; Other attributes\n",
    "HTML elements can also include other attributes, which can be equally useful for identifying and targeting specific data points. To locate these attributes, search for them using the same method as you do for CSS selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3leok25jS5t",
    "outputId": "4b59e02a-312d-4d74-c98e-524157ccb92b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(meta=\"Youngest sister\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBKjBGRHBHds"
   },
   "source": [
    "#### 3.1.3.&nbsp; Searching by string\n",
    "The text (string) is the part between the opening and closing angle brackets, this is what's displayed on the webpage. For example, below, these brackets have `Elsie` as the text.\n",
    "\n",
    "`<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>`\n",
    "\n",
    "Instead of searching for specific tags or attributes, you can also search for this text. To do this, you can use a string or a regular expression to specify the text you're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6JWfJ65A_tl",
    "outputId": "31fcc546-f64c-4d6a-d4b8-aa151e14fee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=\"Dormouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tilKV8RJX6Sl"
   },
   "source": [
    "The string \"Dormouse\" didn't return any results because BeautifulSoup searches for entire strings that exactly match the string you entered. In other words, the string must be the exact same as what you're searching for for it to be considered a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgD4tC63CMcM",
    "outputId": "cd000325-85d6-4a51-c718-45c162e37b8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\", \"The Dormouse's story\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string=\"The Dormouse's story\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ji8otCeHYT0-"
   },
   "source": [
    "To search for a substring, the easiest way is to use the regular expressions method `.compile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a-9m5zNmxok",
    "outputId": "1084305a-4e44-41ea-f8b3-b9689c22b9fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The Dormouse's story\", \"The Dormouse's story\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "soup.find_all(string=re.compile(\"dormouse\", re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEZWgddkZJkx"
   },
   "source": [
    "> **Note:** by default, the .compile() method is case-sensitive, meaning it will only match strings that are exactly equal to the pattern you specify, including case. To perform case-insensitive matching, you must explicitly pass the re.IGNORECASE flag to the .compile() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ROMgD-y9mZU"
   },
   "source": [
    "### 3.2.&nbsp; Extracting text\n",
    "There are a few ways to extract text in Beautiful Soup, here we'll focus on 2 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs9mUvTI9oZN"
   },
   "source": [
    "#### 3.2.1.&nbsp; `.get_text()`\n",
    "The `.get_text()` method extracts all the human-readable text from a Beautiful Soup object, returning it as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_x-R0WQm9n-L",
    "outputId": "3365f74f-c17b-4e6c-9824-0684be32a7e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "T4aPfFuT4CUi",
    "outputId": "5d72fdb3-7cfc-4eea-fd68-b5206cbd8d0a"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-d917b23c233b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2308\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   2309\u001b[0m             \u001b[0;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "soup.find_all(\"title\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOgNw4TAAbXj"
   },
   "source": [
    "> Read the error message and look at the output from the cell above. Can you work out why we got an error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mgI1c4Ts4O67",
    "outputId": "e766d3ea-fc62-429d-97f7-7bfa91f8ab35"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The Dormouse's story\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Click `show code` to see the solution to the error\n",
    "\n",
    "# It was a list, read the error messages and notice the square brackets in the original output\n",
    "# Therefore, we need to select the first and only element of this list\n",
    "soup.find_all(\"title\")[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ9rd5VgCDhz"
   },
   "source": [
    "We can also print out multiple items using our looping skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGru8IYF4SQn",
    "outputId": "8ab71fcb-a87b-4fc0-d0da-943c1c052a37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"><b>The Dormouse's story</b></p>,\n",
       " <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a> and\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>;\n",
       " and they lived at the bottom of a well.</p>,\n",
       " <p class=\"story\">...</p>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = soup.find_all(\"p\")\n",
    "story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HG6TMWf54X3N",
    "outputId": "2e504360-3d94-4fc3-becf-12cee1f93075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dormouse's story\n",
      "Once upon a time there were three little sisters; and their names were\n",
      "Elsie,\n",
      "Lacie and\n",
      "Tillie;\n",
      "and they lived at the bottom of a well.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for p in story:\n",
    "  print(p.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUh2ZYo-9x-S"
   },
   "source": [
    "#### 3.2.2.&nbsp; Extracting attributes:\n",
    "HTML elements often store additional information within their attributes. To extract this data using Beautiful Soup, you can append square brackets after the element selector and specify the attribute name within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdqcP4nHECTF",
    "outputId": "cdf6bd95-1756-4c5b-f1dd-8ab0f472d9ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"link1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4x4t_mqjDgqb",
    "outputId": "cefa8ad7-32cf-4405-cb6e-69523d897454"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'http://example.com/elsie'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"link1\")[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7uIkOhD1PmlX",
    "outputId": "03aece4b-2c7b-47c0-c2f4-ee56155e2d11"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Eldest sister'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"link1\")[0]['meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVZJOh1_l0Rt"
   },
   "source": [
    "## Challenge 1 üòÄ\n",
    "Below is new HTML code. Use your scrapping skills to answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lAHzu1Dl2X0"
   },
   "outputs": [],
   "source": [
    "geography = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head> Geography</head>\n",
    "<body>\n",
    "\n",
    "<div class=\"city\">\n",
    "  <h2>London</h2>\n",
    "  <p>London is the most popular tourist destination in the world.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"city\">\n",
    "  <h2>Paris</h2>\n",
    "  <p>Paris was originally a Roman City called Lutetia.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"country\">\n",
    "  <h2>Spain</h2>\n",
    "  <p>Spain produces 43,8% of all the world's Olive Oil.</p>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KOBMEQNl9EZ"
   },
   "outputs": [],
   "source": [
    "# Create the \"soup\"\n",
    "soup_2 = BeautifulSoup(geography, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7XQtTzcl9B0",
    "outputId": "c50837e6-d9d5-474b-8fbb-72262516c5a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London is the most popular tourist destination in the world.',\n",
       " 'Paris was originally a Roman City called Lutetia.',\n",
       " \"Spain produces 43,8% of all the world's Olive Oil.\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. All the \"fun facts\"\n",
    "fun_facts = [p.get_text() for p in soup_2.find_all('p')]\n",
    "fun_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucD8rudDl8_L",
    "outputId": "3a91674c-a2fb-4501-f05f-0f812fe98ebb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London', 'Paris', 'Spain']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. The names of all the places.\n",
    "place_names = [h2.get_text() for h2 in soup_2.find_all('h2')]\n",
    "place_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0K0UQ2V4l88n",
    "outputId": "5e45c696-6999-4f66-91e2-a747c0fcdbff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'London',\n",
       "  'fact': 'London is the most popular tourist destination in the world.'},\n",
       " {'name': 'Paris',\n",
       "  'fact': 'Paris was originally a Roman City called Lutetia.'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. All the content (name and fact) of all the cities (only cities, not countries!)\n",
    "cities = soup_2.find_all('div', class_='city')\n",
    "city_contents = [{\"name\": city.h2.get_text(), \"fact\": city.p.get_text()} for city in cities]\n",
    "city_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNyiqAEll85q",
    "outputId": "a4904436-b9da-4f82-e9e1-2445bf605b30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['London', 'Paris']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. The names (not facts!) of all the cities (not countries!)\n",
    "city_names = [city.h2.get_text() for city in cities]\n",
    "city_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zgq5kkTFk8Dg"
   },
   "source": [
    "---\n",
    "## 4.&nbsp; Navigating html with a few more advanced techniques üó∫Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhTryrEV8tu2"
   },
   "source": [
    "### 4.1.&nbsp; `.find()`\n",
    "`.find()` is similar to `.find_all()`, but it returns only the first element that matches the specified criteria. This makes it useful when you know exactly where the element you're looking for is located and you only need to retrieve one instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZjtVNi38sPY",
    "outputId": "016c88b5-8ffb-4bcc-bd96-fc37eedbb2bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"title\"><b>The Dormouse's story</b></p>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOseQNrW8ueb"
   },
   "source": [
    "### 4.2.&nbsp; `.select()`\n",
    "`.select()` is similar to `.find_all()`, but there are 2 main differences:\n",
    "- the way we write our query in the brackets is slightly different\n",
    "- `.select()` allows you to chain CSS selectors together to navigate through the HTML structure, enabling you to select elements based on their positions within nested elements or patterns. This makes it particularly useful for extracting data from complex HTML structures.\n",
    "\n",
    "In contrast, `.find_all()` uses a simpler syntax based on tag names and attributes, making it more straightforward for basic element selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlLEdmYJK6hB"
   },
   "source": [
    "Here's how we query with `.find_all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPplvgpe8sL_",
    "outputId": "357d37ef-bdbb-4e71-ba4e-e22ee5986377"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a', class_='sister')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZVv18muK-rK"
   },
   "source": [
    "Here's the same query with `.select()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rhc1_2IJJGrz",
    "outputId": "587d4dbc-4cc9-4615-9cb8-712ee2714263"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\" meta=\"Eldest sister\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('a.sister')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg8OUGS9LC42"
   },
   "source": [
    "To demonstrate the power of `.select()` in navigating through nested elements, let's extract all the `<a>` tags with the id `'link2'` that are within `<p>` tags with the class `'story'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfBvxRUzJMgM",
    "outputId": "feebde62-69fe-45db-e3b1-4d38690b2408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('p.story a#link2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0tGSzydlcjt"
   },
   "source": [
    "### 4.3.&nbsp; Navigating to the Next or Previous Element\n",
    "In some cases, you may need to access specific elements that are closely related to others, but their HTML structure doesn't provide unique identifiers. To overcome this challenge, you can utilise the `.find_next()` and `.find_previous()` methods to navigate through the HTML structure and reach the desired element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWBJnwKh6xAM",
    "outputId": "882b89c8-c0df-4750-ef4b-d0c3161ad7d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\" meta=\"Youngest sister\">Tillie</a>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_link = soup.find(id='link3')\n",
    "last_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox3xJJOP0fhD"
   },
   "source": [
    "#### 4.1.1.&nbsp; `.find_next()`\n",
    "`.find_next()` moves forward one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrBfI5c40fTE",
    "outputId": "7b5919b9-567e-4ed6-b650-f43fcfb84bd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"story\">...</p>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_link.find_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMGziu0x0klO"
   },
   "source": [
    "#### 4.2.&nbsp; `.find_previous()`\n",
    "`.find_previous()` moves back one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKMSnJKgwjO3",
    "outputId": "da2af33e-57bb-4a76-9c44-0dbf17e0c731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\" meta=\"Middle sister\">Lacie</a>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_link.find_previous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGSarkvdVkpj"
   },
   "source": [
    "---\n",
    "## 5.&nbsp; Showcasing these skills on a real website üíª\n",
    "Let's see what information we can get from the wikipedia site for web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ztc-9lpTm2e9"
   },
   "source": [
    "### Loading the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-qyiClnVptT"
   },
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Web_scraping\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup_3 = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo-b2kLwNOWW"
   },
   "source": [
    "> While we haven't yet looked into the requests library, we'll postpone delving into it today to avoid overwhelming you with too much new information. Instead, we'll explore the requests library when we start gathering weather data later in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87Mhk3AwX9Wj",
    "outputId": "9b95ffd4-d226-45f9-f60c-74642c980587"
   },
   "outputs": [],
   "source": [
    "print(soup_3.prettify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wBsdqjum_o_"
   },
   "source": [
    "### Getting the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2V9-cuYsWVLP",
    "outputId": "fe9e5f95-59b7-4202-ec3d-6097ccc3e511"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Web scraping - Wikipedia'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_3.find(\"title\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGZWvJFmnLZp"
   },
   "source": [
    "### Getting the first h1 tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QejF-CVDWdVE",
    "outputId": "b363230c-9fbe-4c10-ce1b-37e2fda6ed98"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Web scraping'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_3.find(\"h1\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0bLXLH-nNyY"
   },
   "source": [
    "### Getting all the h2 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jcx15L3XWk98",
    "outputId": "f6a63549-9293-4b0e-c1e3-d8dd4ecf0cab"
   },
   "outputs": [],
   "source": [
    "h2_tags = soup_3.find_all(\"h2\")\n",
    "h2_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPWXrxtAnSR-"
   },
   "source": [
    "As we have multiple tags in the list here, we need to use a loop to print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-Lw4pCEW7Uy",
    "outputId": "14978215-cb3d-4928-b3a8-c963288028f8"
   },
   "outputs": [],
   "source": [
    "for h2 in h2_tags:\n",
    "  print(h2.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIyT3sijoGuK"
   },
   "source": [
    "### Selecting the `Legal Issues` text for only `India`\n",
    "> **Pro tip:** If you're using Google Chrome, you can navigate to `View > Developer > Inspect elements` to access the built-in web development tools. Here, you can explore the HTML structure of the webpage directly within the browser using your mouse. This interactive approach is often more intuitive than examining the raw HTML code.\n",
    "\n",
    "By investigating the html we can see that the closest, easy to access, tag is the heading with the CSS `id` of `\"India\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQkUGkeoh0G_",
    "outputId": "8a3cb5a1-ea0e-47d3-fd2c-dd893e188aa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"mw-headline\" id=\"India\">India</span>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_3.find(id=\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYx5YrJKoh4a"
   },
   "source": [
    "We can then use `.find_next()` to select the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLxrYkO3hbZn",
    "outputId": "e5c2f075-abab-4264-b402-8078ab816946"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Web_scraping&amp;action=edit&amp;section=16\" title=\"Edit section: India\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_3.find(id=\"India\").find_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q67eh_Oxo7B2"
   },
   "source": [
    "Looks like the next tag was a `span` tag, so let's specify that we want the next `p` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oU-Ai8-Vgdsw",
    "outputId": "9d0fdf09-da1c-4068-8e9d-9551df3c2517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Leaving a few cases dealing with IPR infringement, Indian courts have not expressly ruled on the legality of web scraping. However, since all common forms of electronic contracts are enforceable in India, violating the terms of use prohibiting data scraping will be a violation of the contract law. It will also violate the <a href=\"/wiki/Information_Technology_Act,_2000#:~:text=From_Wikipedia,_the_free_encyclopedia_The_Information_Technology,in_India_dealing_with_cybercrime_and_electronic_commerce.\" title=\"Information Technology Act, 2000\">Information Technology Act, 2000</a>, which penalizes unauthorized access to a computer resource or extracting data from a computer resource.\n",
       "</p>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_3.find(id=\"India\").find_next(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b53SGH5pFwb"
   },
   "source": [
    "Now we can simply extract the text, and we have what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "UP5YwO3ii3NR",
    "outputId": "5e188868-f214-4bd3-cc42-3724b7229b76"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Leaving a few cases dealing with IPR infringement, Indian courts have not expressly ruled on the legality of web scraping. However, since all common forms of electronic contracts are enforceable in India, violating the terms of use prohibiting data scraping will be a violation of the contract law. It will also violate the Information Technology Act, 2000, which penalizes unauthorized access to a computer resource or extracting data from a computer resource.\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_3.find(id=\"India\").find_next(\"p\").get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4QQbALMuZ99"
   },
   "source": [
    "## Challenge 2 üòÄ\n",
    "\n",
    "Utilise your web scraping skills to gather information about three German cities ‚Äì Berlin, Hamburg, and Munich ‚Äì from Wikipedia. You will start by extracting basic information: the country, the latitude and the longitude of each city and then expand to more dynamic data such as the population.\n",
    "\n",
    "1. Scraping Basic Information\n",
    "\n",
    "  1.1. Begin by scraping the country, the latitude and the longitude of each city from their respective Wikipedia pages:\n",
    "\n",
    " - Berlin: https://en.wikipedia.org/wiki/Berlin\n",
    " - Hamburg: https://en.wikipedia.org/wiki/Hamburg\n",
    " - Munich: https://en.wikipedia.org/wiki/Munich\n",
    "\n",
    "  1.2. Once you have scraped the basic information of each city, reflect on the similarities and patterns in accessing them across the three pages. Also, analyse the URLs to identify any commonalities. Make a loop that executes once and retrieves the country, latitude, and longitude for all three cities.\n",
    "\n",
    "2. Data Organisation\n",
    "\n",
    "  2.1 Utilise pandas DataFrame to effectively store the extracted information. This DataFrame should have a row for each city, and columns for each type of information (cityname, country, latitude, longitude). If you feel brave, change latitude and longitude into decimal format.\n",
    "\n",
    "  2.2 Looking ahead (optional): Create a function from the loop and DataFrame to encapsulate the scraping process. This function can be used repeatedly to fetch updated data whenever necessary. It should return a clean, properly formatted DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_nJj6Gy5iso"
   },
   "source": [
    "## BONUS Challenge 3: Population\n",
    "\n",
    "  3.1. Expand the scope of your data gathering by extracting the population of a city. This information changes over time, so we might need to add a timestamp.\n",
    "\n",
    "  3.2. Organise your information in a DataFrame and wrap it in a separate function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbbmxiK35iqh"
   },
   "source": [
    "## BONUS Challenge 4: Global Data Scraping\n",
    "\n",
    "  With your robust scraping skills now honed, venture beyond the confines of Germany and explore other cities around the world. While the extraction methodology for German cities may follow a consistent pattern, this may not be the case for cities from different countries. Can you make a function that returns a clean DataFrame of information for cities worldwide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-aBO4bYE80q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
